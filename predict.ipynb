{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/arhan/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: transformers in /Users/arhan/anaconda3/lib/python3.11/site-packages (4.32.1)\n",
      "Requirement already satisfied: torch in /Users/arhan/anaconda3/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/arhan/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: filelock in /Users/arhan/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/arhan/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/arhan/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/arhan/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/arhan/anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas transformers torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            source_id         source_name              author  \\\n",
      "0             reuters             Reuters   Reuters Editorial   \n",
      "1     the-irish-times     The Irish Times  Eoin Burke-Kennedy   \n",
      "2     the-irish-times     The Irish Times   Deirdre McQuillan   \n",
      "3  al-jazeera-english  Al Jazeera English          Al Jazeera   \n",
      "4            bbc-news            BBC News            BBC News   \n",
      "\n",
      "                                               title  \\\n",
      "0  NTSB says Autopilot engaged in 2018 California...   \n",
      "1       Unemployment falls to post-crash low of 5.2%   \n",
      "2  \"Louise Kennedy AW2019: Long coats, sparkling ...   \n",
      "3  North Korean footballer Han joins Italian gian...   \n",
      "4  UK government lawyer says proroguing parliamen...   \n",
      "\n",
      "                                         description  \\\n",
      "0  \"The National Transportation Safety Board said...   \n",
      "1  Latest monthly figures reflect continued growt...   \n",
      "2  Autumn-winter collection features designer’s g...   \n",
      "3  Han is the first North Korean player in the Se...   \n",
      "4  \"The UK government's lawyer, David Johnston ar...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.reuters.com/article/us-tesla-crash...   \n",
      "1  https://www.irishtimes.com/business/economy/un...   \n",
      "2  https://www.irishtimes.com/\\t\\t\\t\\t\\t\\t\\t/life...   \n",
      "3  https://www.aljazeera.com/news/2019/09/north-k...   \n",
      "4  https://www.bbc.co.uk/news/av/uk-scotland-4956...   \n",
      "\n",
      "                                        url_to_image          published_at  \\\n",
      "0  https://s4.reutersmedia.net/resources/r/?m=02&...  2019-09-03T16:22:20Z   \n",
      "1  https://www.irishtimes.com/image-creator/?id=1...  2019-09-03T10:32:28Z   \n",
      "2  https://www.irishtimes.com/image-creator/?id=1...  2019-09-03T14:40:00Z   \n",
      "3  https://www.aljazeera.com/mritems/Images/2019/...  2019-09-03T17:25:39Z   \n",
      "4  https://ichef.bbci.co.uk/news/1024/branded_new...  2019-09-03T14:39:21Z   \n",
      "\n",
      "                                             content  top_article  \\\n",
      "0  \"WASHINGTON (Reuters) - The National Transport...          0.0   \n",
      "1  \"The States jobless rate fell to 5.2 per cent ...          0.0   \n",
      "2  \"Louise Kennedy is showing off her autumn-wint...          1.0   \n",
      "3  \"Han Kwang Song, the first North Korean footba...          0.0   \n",
      "4                                                NaN          0.0   \n",
      "\n",
      "   engagement_reaction_count  engagement_comment_count  \\\n",
      "0                        0.0                       0.0   \n",
      "1                        6.0                      10.0   \n",
      "2                        NaN                       NaN   \n",
      "3                        0.0                       0.0   \n",
      "4                        0.0                       0.0   \n",
      "\n",
      "   engagement_share_count  engagement_comment_plugin_count  \n",
      "0                  2528.0                              0.0  \n",
      "1                     2.0                              0.0  \n",
      "2                     NaN                              NaN  \n",
      "3                     7.0                              0.0  \n",
      "4                     0.0                              0.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1428 entries, 0 to 1427\n",
      "Data columns (total 14 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   source_id                        1428 non-null   object \n",
      " 1   source_name                      1428 non-null   object \n",
      " 2   author                           1317 non-null   object \n",
      " 3   title                            1428 non-null   object \n",
      " 4   description                      1424 non-null   object \n",
      " 5   url                              1427 non-null   object \n",
      " 6   url_to_image                     1327 non-null   object \n",
      " 7   published_at                     1427 non-null   object \n",
      " 8   content                          1262 non-null   object \n",
      " 9   top_article                      1426 non-null   float64\n",
      " 10  engagement_reaction_count        1414 non-null   float64\n",
      " 11  engagement_comment_count         1414 non-null   float64\n",
      " 12  engagement_share_count           1414 non-null   float64\n",
      " 13  engagement_comment_plugin_count  1414 non-null   float64\n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 156.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = '/Users/arhan/Documents/usa/ddp/facebook_engagement_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values and general information\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source_id', 'source_name', 'author', 'title', 'description', 'url',\n",
      "       'url_to_image', 'published_at', 'content', 'top_article',\n",
      "       'engagement_reaction_count', 'engagement_comment_count',\n",
      "       'engagement_share_count', 'engagement_comment_plugin_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print all column names in the DataFrame\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a total engagement score by summing relevant metrics\n",
    "data['total_engagement'] = data['engagement_reaction_count'] + data['engagement_comment_count'] + data['engagement_share_count'] + data['engagement_comment_plugin_count']\n",
    "\n",
    "# Define a threshold for good engagement\n",
    "threshold = data['total_engagement'].quantile(0.75)  # Using the 75th percentile as the threshold\n",
    "\n",
    "# Create a new binary column based on this threshold\n",
    "data['label'] = (data['total_engagement'] >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ensure the content column is a string and replace NaN values\n",
    "data['content'] = data['content'].fillna('').astype(str)\n",
    "\n",
    "# Tokenize text\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Apply tokenization\n",
    "data['input_ids'] = data['content'].apply(lambda x: tokenize_function(x)['input_ids'].squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data['input_ids'], data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to tokenize data\n",
    "def tokenize_data(data):\n",
    "    return tokenizer(data, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize the entire dataset\n",
    "tokenized_texts = tokenize_data(data['content'].tolist())\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    tokenized_texts['input_ids'], data['label'], test_size=0.2\n",
    ")\n",
    "\n",
    "# Ensure labels are also tensors\n",
    "train_labels = torch.tensor(train_labels.values)\n",
    "val_labels = torch.tensor(val_labels.values)\n",
    "\n",
    "# Prepare datasets using the correct PyTorch dataset and DataLoader utilities\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(train_texts, train_labels)\n",
    "val_dataset = TensorDataset(val_texts, val_labels)\n",
    "\n",
    "# DataLoader setup\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize the entire dataset\n",
    "tokenized_texts = tokenizer(data['content'].tolist(), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Generate indices and split them\n",
    "indices = np.arange(len(data['label']))\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.2)\n",
    "\n",
    "# Use the indices to create training and validation datasets\n",
    "train_texts = {key: val[train_indices] for key, val in tokenized_texts.items()}\n",
    "val_texts = {key: val[val_indices] for key, val in tokenized_texts.items()}\n",
    "train_labels = data['label'].values[train_indices]\n",
    "val_labels = data['label'].values[val_indices]\n",
    "\n",
    "# Create instances of the CustomDataset\n",
    "train_dataset = CustomDataset(train_texts, train_labels)\n",
    "val_dataset = CustomDataset(val_texts, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load BERT for sequence classification with two labels (good or bad engagement)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',  # Make sure this directory is accessible and writable\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",  # This will save the model at each logging step; consider adjusting if too frequent\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1  # Optionally add this to limit the number of saved models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                          # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                   # training arguments, defined above\n",
    "    train_dataset=train_dataset,          # training dataset\n",
    "    eval_dataset=val_dataset              # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75738293ae254b51850d1ab863188f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/30/3s3tphn117b7hrs3h7xw1pr80000gn/T/ipykernel_58758/1591585656.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3761, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9e5ce9246d4aeb8cf8378f05949f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4884822368621826, 'eval_runtime': 2.2116, 'eval_samples_per_second': 129.317, 'eval_steps_per_second': 8.139, 'epoch': 0.07}\n",
      "{'loss': 0.4179, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22eebd642ce347189181c0e96ee97646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.448639988899231, 'eval_runtime': 2.2026, 'eval_samples_per_second': 129.849, 'eval_steps_per_second': 8.172, 'epoch': 0.14}\n",
      "{'loss': 0.1636, 'learning_rate': 3e-06, 'epoch': 0.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd70584fc4246efa9c88aee638db0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4399183988571167, 'eval_runtime': 2.2119, 'eval_samples_per_second': 129.302, 'eval_steps_per_second': 8.138, 'epoch': 0.21}\n",
      "{'loss': 0.4702, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becdd3de075e4b1abf1592d69720d38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.411758542060852, 'eval_runtime': 2.1996, 'eval_samples_per_second': 130.025, 'eval_steps_per_second': 8.183, 'epoch': 0.28}\n",
      "{'loss': 0.1659, 'learning_rate': 5e-06, 'epoch': 0.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b2238bed4d47009fbf959cad7c787f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3993489742279053, 'eval_runtime': 2.1945, 'eval_samples_per_second': 130.325, 'eval_steps_per_second': 8.202, 'epoch': 0.35}\n",
      "{'loss': 0.3006, 'learning_rate': 6e-06, 'epoch': 0.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a313f9144c4b6c9b380111e2d4b8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.372585654258728, 'eval_runtime': 2.2083, 'eval_samples_per_second': 129.509, 'eval_steps_per_second': 8.151, 'epoch': 0.42}\n",
      "{'loss': 0.2829, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01eec7dac60749fbb73ae52c08e3c235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3514454364776611, 'eval_runtime': 2.198, 'eval_samples_per_second': 130.12, 'eval_steps_per_second': 8.189, 'epoch': 0.49}\n",
      "{'loss': 0.0646, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31132570004046ecb2f0a80a8be23f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.377900242805481, 'eval_runtime': 2.2137, 'eval_samples_per_second': 129.193, 'eval_steps_per_second': 8.131, 'epoch': 0.56}\n",
      "{'loss': 0.1806, 'learning_rate': 9e-06, 'epoch': 0.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdeab451c794746a557fb4cdbf19f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4208205938339233, 'eval_runtime': 2.1956, 'eval_samples_per_second': 130.26, 'eval_steps_per_second': 8.198, 'epoch': 0.63}\n",
      "{'loss': 0.2291, 'learning_rate': 1e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df83bffee664b808fefb5ea1f5ffdac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4350793361663818, 'eval_runtime': 2.2054, 'eval_samples_per_second': 129.679, 'eval_steps_per_second': 8.162, 'epoch': 0.7}\n",
      "{'loss': 0.3837, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288e744387fe4b2aabc457da9b96d1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4039942026138306, 'eval_runtime': 2.2628, 'eval_samples_per_second': 126.391, 'eval_steps_per_second': 7.955, 'epoch': 0.77}\n",
      "{'loss': 0.1562, 'learning_rate': 1.2e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddce546195394e51b1b3e7b64e1faa02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3498789072036743, 'eval_runtime': 2.1961, 'eval_samples_per_second': 130.234, 'eval_steps_per_second': 8.197, 'epoch': 0.84}\n",
      "{'loss': 0.1938, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e8641ce41b4096a969730890883da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3453428745269775, 'eval_runtime': 2.1974, 'eval_samples_per_second': 130.153, 'eval_steps_per_second': 8.191, 'epoch': 0.91}\n",
      "{'loss': 0.1788, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b47778346b3401099ea6ebd4b909ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3454093933105469, 'eval_runtime': 2.206, 'eval_samples_per_second': 129.646, 'eval_steps_per_second': 8.16, 'epoch': 0.98}\n",
      "{'loss': 0.2005, 'learning_rate': 1.5e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8386882c24164179ac8d0f04c36db711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4114845991134644, 'eval_runtime': 2.2108, 'eval_samples_per_second': 129.363, 'eval_steps_per_second': 8.142, 'epoch': 1.05}\n",
      "{'loss': 0.1897, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e6b9250c8449fea93b2ab575468bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.423384428024292, 'eval_runtime': 2.2012, 'eval_samples_per_second': 129.927, 'eval_steps_per_second': 8.177, 'epoch': 1.12}\n",
      "{'loss': 0.1013, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1.19}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3d5c56f5c641b28eeb6f5ac9f03f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.499271035194397, 'eval_runtime': 2.2084, 'eval_samples_per_second': 129.507, 'eval_steps_per_second': 8.151, 'epoch': 1.19}\n",
      "{'loss': 0.312, 'learning_rate': 1.8e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e9d3e72f0f4667b621cc9063b35b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3387330770492554, 'eval_runtime': 2.2251, 'eval_samples_per_second': 128.535, 'eval_steps_per_second': 8.09, 'epoch': 1.26}\n",
      "{'loss': 0.1138, 'learning_rate': 1.9e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fdfbf239b04b6ea6abb3cd15664e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3291295766830444, 'eval_runtime': 2.1965, 'eval_samples_per_second': 130.206, 'eval_steps_per_second': 8.195, 'epoch': 1.33}\n",
      "{'loss': 0.065, 'learning_rate': 2e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24070fbaa4b84af8953de822a9cedcef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5769582986831665, 'eval_runtime': 2.1975, 'eval_samples_per_second': 130.151, 'eval_steps_per_second': 8.191, 'epoch': 1.4}\n",
      "{'loss': 0.4606, 'learning_rate': 2.1e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4274fb05eb43c38928776a16c275c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1912544965744019, 'eval_runtime': 2.1988, 'eval_samples_per_second': 130.068, 'eval_steps_per_second': 8.186, 'epoch': 1.47}\n",
      "{'loss': 0.1784, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4e9097732e4ae4be7997cd21595d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.108616828918457, 'eval_runtime': 2.7728, 'eval_samples_per_second': 103.144, 'eval_steps_per_second': 6.492, 'epoch': 1.54}\n",
      "{'loss': 0.238, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1564e1fb7c4aba93199b2230c3f366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.258121132850647, 'eval_runtime': 2.2225, 'eval_samples_per_second': 128.681, 'eval_steps_per_second': 8.099, 'epoch': 1.61}\n",
      "{'loss': 0.2984, 'learning_rate': 2.4e-05, 'epoch': 1.68}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f16d5bab8e470ebec78cddf7e46ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3241628408432007, 'eval_runtime': 2.2245, 'eval_samples_per_second': 128.569, 'eval_steps_per_second': 8.092, 'epoch': 1.68}\n",
      "{'loss': 0.086, 'learning_rate': 2.5e-05, 'epoch': 1.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f937955d551a483aacdb32fd9fd4c6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5871912240982056, 'eval_runtime': 2.2197, 'eval_samples_per_second': 128.848, 'eval_steps_per_second': 8.109, 'epoch': 1.75}\n",
      "{'loss': 0.2678, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02079a5629ef4833888ad9a3d8b9745a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4606475830078125, 'eval_runtime': 2.2655, 'eval_samples_per_second': 126.244, 'eval_steps_per_second': 7.945, 'epoch': 1.82}\n",
      "{'loss': 0.2538, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270abe01d64b4683a29276338fd4c95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4433013200759888, 'eval_runtime': 2.201, 'eval_samples_per_second': 129.944, 'eval_steps_per_second': 8.178, 'epoch': 1.89}\n",
      "{'loss': 0.281, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1ab2c9e13749efa9827e2235761f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4645161628723145, 'eval_runtime': 2.2051, 'eval_samples_per_second': 129.698, 'eval_steps_per_second': 8.163, 'epoch': 1.96}\n",
      "{'loss': 0.078, 'learning_rate': 2.9e-05, 'epoch': 2.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50aa2dbbb5404751b476b2735ec95cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.596764087677002, 'eval_runtime': 2.2044, 'eval_samples_per_second': 129.74, 'eval_steps_per_second': 8.165, 'epoch': 2.03}\n",
      "{'loss': 0.0704, 'learning_rate': 3e-05, 'epoch': 2.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f411fdcf66ad47ddbf67f85e8696c52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.611722469329834, 'eval_runtime': 2.2879, 'eval_samples_per_second': 125.004, 'eval_steps_per_second': 7.867, 'epoch': 2.1}\n",
      "{'loss': 0.0882, 'learning_rate': 3.1e-05, 'epoch': 2.17}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8900d62646640528cd741dad3af7fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.831849217414856, 'eval_runtime': 2.2187, 'eval_samples_per_second': 128.903, 'eval_steps_per_second': 8.113, 'epoch': 2.17}\n",
      "{'loss': 0.0813, 'learning_rate': 3.2000000000000005e-05, 'epoch': 2.24}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1db37f2643451ca866c051516a1e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8581395149230957, 'eval_runtime': 2.2221, 'eval_samples_per_second': 128.708, 'eval_steps_per_second': 8.101, 'epoch': 2.24}\n",
      "{'loss': 0.2806, 'learning_rate': 3.3e-05, 'epoch': 2.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8093d226ca494299f82029889a8cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6808933019638062, 'eval_runtime': 2.2034, 'eval_samples_per_second': 129.802, 'eval_steps_per_second': 8.169, 'epoch': 2.31}\n",
      "{'loss': 0.5965, 'learning_rate': 3.4000000000000007e-05, 'epoch': 2.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b50924d604444baa68d7f0415a4225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4267948865890503, 'eval_runtime': 2.1989, 'eval_samples_per_second': 130.067, 'eval_steps_per_second': 8.186, 'epoch': 2.38}\n",
      "{'loss': 0.1442, 'learning_rate': 3.5e-05, 'epoch': 2.45}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2c93b975754dc49b52dc1ac6e05c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4531431198120117, 'eval_runtime': 2.1986, 'eval_samples_per_second': 130.083, 'eval_steps_per_second': 8.187, 'epoch': 2.45}\n",
      "{'loss': 0.1621, 'learning_rate': 3.6e-05, 'epoch': 2.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d482fedebb74030bec00fdb42027423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5814496278762817, 'eval_runtime': 2.2405, 'eval_samples_per_second': 127.649, 'eval_steps_per_second': 8.034, 'epoch': 2.52}\n",
      "{'loss': 0.3243, 'learning_rate': 3.7e-05, 'epoch': 2.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8ece9b15514f8ea6870b97d2b5471d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1472994089126587, 'eval_runtime': 2.2055, 'eval_samples_per_second': 129.673, 'eval_steps_per_second': 8.161, 'epoch': 2.59}\n",
      "{'loss': 0.3642, 'learning_rate': 3.8e-05, 'epoch': 2.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a75cd2c2a34d66b0d7a82d3bf37963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0359492301940918, 'eval_runtime': 2.2076, 'eval_samples_per_second': 129.55, 'eval_steps_per_second': 8.154, 'epoch': 2.66}\n",
      "{'loss': 0.2702, 'learning_rate': 3.9000000000000006e-05, 'epoch': 2.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678e4cec1e5e4621bcb9789eb00cdffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4528601169586182, 'eval_runtime': 2.2587, 'eval_samples_per_second': 126.619, 'eval_steps_per_second': 7.969, 'epoch': 2.73}\n",
      "{'loss': 0.2655, 'learning_rate': 4e-05, 'epoch': 2.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7166f33d91384d85b65fcb91423a7f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1228612661361694, 'eval_runtime': 2.2037, 'eval_samples_per_second': 129.779, 'eval_steps_per_second': 8.168, 'epoch': 2.8}\n",
      "{'loss': 0.2922, 'learning_rate': 4.1e-05, 'epoch': 2.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6465c488dbce4d3cb8585f906a9c0c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1578338146209717, 'eval_runtime': 2.2028, 'eval_samples_per_second': 129.833, 'eval_steps_per_second': 8.171, 'epoch': 2.87}\n",
      "{'loss': 0.364, 'learning_rate': 4.2e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775f274ff0344cd78ab2c1db17163621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1692448854446411, 'eval_runtime': 2.2014, 'eval_samples_per_second': 129.917, 'eval_steps_per_second': 8.177, 'epoch': 2.94}\n",
      "{'train_runtime': 248.3854, 'train_samples_per_second': 13.793, 'train_steps_per_second': 1.727, 'train_loss': 0.23953617244333655, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=429, training_loss=0.23953617244333655, metrics={'train_runtime': 248.3854, 'train_samples_per_second': 13.793, 'train_steps_per_second': 1.727, 'train_loss': 0.23953617244333655, 'epoch': 3.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/30/3s3tphn117b7hrs3h7xw1pr80000gn/T/ipykernel_58758/1591585656.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a56e6e21b54046915c422f1cf8b94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0741196870803833, 'eval_runtime': 2.9514, 'eval_samples_per_second': 96.902, 'eval_steps_per_second': 6.099, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./results/tokenizer_config.json',\n",
       " './results/special_tokens_map.json',\n",
       " './results/vocab.txt',\n",
       " './results/added_tokens.json')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./results')\n",
    "tokenizer.save_pretrained('./results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer and model from the saved directory\n",
    "tokenizer = BertTokenizer.from_pretrained('./results')\n",
    "model = BertForSequenceClassification.from_pretrained('./results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(caption):\n",
    "    # Tokenize the caption\n",
    "    inputs = tokenizer(caption, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_caption(caption):\n",
    "    # Prepare the input\n",
    "    inputs = prepare_input(caption)\n",
    "    \n",
    "    # Move the inputs to the same device as the model\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "\n",
    "    # Evaluate the model (inference)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        predictions = probabilities.argmax(dim=1).item()\n",
    "    \n",
    "    return \"Good engagement\" if predictions == 1 else \"Bad engagement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad engagement\n"
     ]
    }
   ],
   "source": [
    "caption = \"Bridging the gap between glam and inclusivity! Just like the cars seamlessly crossing the highway bridge, Fenty Beauty by Rihanna brings together unmatched shades for ALL skin tones. #InclusiveBeauty 🌈✨🚗\"\n",
    "result = evaluate_caption(caption)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_caption_with_probabilities(caption):\n",
    "    # Prepare the input\n",
    "    inputs = prepare_input(caption)\n",
    "    \n",
    "    # Move the inputs to the same device as the model\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "\n",
    "    # Evaluate the model (inference)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        predicted_class = probabilities.argmax(dim=1).item()\n",
    "        confidence = probabilities[0, predicted_class].item()\n",
    "\n",
    "    return f\"Caption classified as {'Good engagement' if predicted_class == 1 else 'Bad engagement'} with {confidence:.2f} confidence\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_caption_with_top_probabilities(caption):\n",
    "    # Prepare the input\n",
    "    inputs = prepare_input(caption)\n",
    "    \n",
    "    # Move the inputs to the same device as the model\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "\n",
    "    # Evaluate the model (inference)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        top_probabilities, top_classes = torch.topk(probabilities, 2)\n",
    "\n",
    "    result = f\"Probabilities: \\n\"\n",
    "    for prob, cls in zip(top_probabilities[0], top_classes[0]):\n",
    "        class_name = \"Good engagement\" if cls.item() == 1 else \"Bad engagement\"\n",
    "        result += f\"{class_name}: {prob.item():.2f}\\n\"\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TextBlob\n",
      "  Obtaining dependency information for TextBlob from https://files.pythonhosted.org/packages/02/07/5fd2945356dd839974d3a25de8a142dc37293c21315729a41e775b5f3569/textblob-0.18.0.post0-py3-none-any.whl.metadata\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from TextBlob) (3.8.1)\n",
      "Requirement already satisfied: click in /Users/arhan/anaconda3/lib/python3.11/site-packages (from nltk>=3.8->TextBlob) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/arhan/anaconda3/lib/python3.11/site-packages (from nltk>=3.8->TextBlob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/arhan/anaconda3/lib/python3.11/site-packages (from nltk>=3.8->TextBlob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/arhan/anaconda3/lib/python3.11/site-packages (from nltk>=3.8->TextBlob) (4.65.0)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: TextBlob\n",
      "Successfully installed TextBlob-0.18.0.post0\n"
     ]
    }
   ],
   "source": [
    "!pip install TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "def evaluate_caption_with_sentiment(caption):\n",
    "    sentiment = TextBlob(caption).sentiment\n",
    "    engagement = evaluate_caption(caption)\n",
    "    return f\"{engagement}. Sentiment polarity: {sentiment.polarity:.2f}, subjectivity: {sentiment.subjectivity:.2f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def evaluate_caption_with_sentiment(caption):\n",
    "    sentiment = TextBlob(caption).sentiment\n",
    "    engagement = evaluate_caption(caption)\n",
    "    return f\"{engagement}. Sentiment polarity: {sentiment.polarity:.2f}, subjectivity: {sentiment.subjectivity:.2f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption classified as Bad engagement with 0.98 confidence\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_caption_with_probabilities(caption)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: \n",
      "Bad engagement: 0.98\n",
      "Good engagement: 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_caption_with_top_probabilities(caption)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad engagement. Sentiment polarity: 0.10, subjectivity: 0.10\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_caption_with_sentiment(caption)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
