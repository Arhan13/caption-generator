# Caption Generator

## Overview
This project utilizes state-of-the-art natural language processing models including BLIP, BERT, GPT-3.5, and GPT-4 Turbo to generate captions for images.

## Features
- **BLIP Integration**: BLIP (Bidirectional Latent Intents with Transformers) model provides contextual understanding, enhancing the quality of generated captions.
- **BERT Support**: Incorporating BERT (Bidirectional Encoder Representations from Transformers) model for fine-tuning and improving the accuracy of generated captions.
- **GPT-3.5 and GPT-4 Turbo**: Leveraging the power of GPT-3.5 and GPT-4 Turbo for natural language generation, ensuring fluent and contextually relevant captions.

## Usage
1. **Setup**: Install the required dependencies listed in the `requirements.txt` file. Using `pip install -r requirements.txt`
2. **Running the project**: `streamlit run index.py`

## Contribution
Contributions to this project are welcome! Whether it's bug fixes, feature enhancements, or documentation improvements, feel free to submit pull requests.

## License
This project is licensed under the [MIT License](LICENSE).

## Acknowledgments
- This project builds upon the advancements in natural language processing enabled by the BLIP, BERT, GPT-3.5, and GPT-4 Turbo models.
